{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Hierarchical and K-means clustering\n",
    "***\n",
    "\n",
    "In this notebook we'll practice clustering data using hierarchical clustering and K-means. Conceptually, neither is particularly difficult to get a handle on, so we will spend most of our time thinking about some of the nitty-gritty details, like computing cluster sizes and determining when to diagnose convergence and stop iterating.\n",
    "\n",
    "We'll need some nice packages for this notebook, so let's load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also will want a helper function to compute the Euclidean distance, so let's define one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x1, x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))\n",
    "\n",
    "#x_1=(x_1 coord 1, x_2 coord 2)\n",
    "#your HW problem will have points of the form:\n",
    "#loc=(X[a,b],Y[a,b]) compared to loc2= (X[c,d],Y[c,d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 1:  Picking initial clusters\n",
    "\n",
    "Suppose we have the following set of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "x1 = stats.multivariate_normal.rvs(mean=[1,1], cov=[[.15,0],[0,.15]], size=5)\n",
    "x2 = stats.multivariate_normal.rvs(mean=[2,2], cov=[[.15,0],[0,.15]], size=6)\n",
    "X = np.concatenate([x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step should always be some form of exploration. So, let's have a look at the data to convince ourselves that there might be some kind of clustered structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2823e77fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "plt.scatter([x[0] for x in X], [x[1] for x in X])\n",
    "plt.axis([0, 3, 0, 3])\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92071706, 1.18549396],\n",
       "       [0.79882225, 0.78476658],\n",
       "       [1.76134354, 1.53966376],\n",
       "       [1.03598307, 1.10911982],\n",
       "       [1.29784116, 1.4827421 ],\n",
       "       [2.39008276, 1.49797572],\n",
       "       [2.1065038 , 2.08865758],\n",
       "       [2.52398244, 2.34331261],\n",
       "       [1.2247692 , 1.855986  ],\n",
       "       [2.64641072, 1.83014267],\n",
       "       [1.79095904, 2.1847355 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so maybe there's a cluster centered around (1.1, 1.4) and another one around (2.2, 2) (or something like that?). Whatever the case, if we have any reason to believe there are multiple clusters going on, if you squint hard enough, this figure has some evidence of clustery behavior.\n",
    "\n",
    "When we start K-means clustering off, we must pick a number of clusters. Obviously, you ran the code above so you know $K=2$ is a great choice, but let's pretend like we didn't know that and we pick $K=3$. Don't even worry though - we'll try $K=2$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few different options for how to start our clustering:\n",
    "1. Pick $K$ data points at random as the initial cluster centroids\n",
    "1. Run a cheaper clustering method (or with a subset of the data) to get an estimate of where the clusters might be\n",
    "1. Pick a point for the first cluster's centroid, then pick a point for the second cluster's centroid that is as far away from the first centroid as possible, and so on up to $K$ centroids.\n",
    "\n",
    "Often, we will want to perform the clustering multiple times with different initial clusters and different numbers of clusters. So, while we want to do as well as we can with good initial conditions and a reasonable choice for $K$, we also can go back and test different choices.\n",
    "\n",
    "Anyway, let's do *none* of the above and instead use a poor man's version of Option 2. The $X_1$ coordinate seems to have the most variation (we could compute the variance to see this), so let's pick our 3 initial centroids as the data points with the most extreme high/low $X_1$ values, and the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's get a list of just the $X_1$ coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9207170643974608, 0.7988222507209873, 1.7613435419601093, 1.035983065935991, 1.2978411597218318, 2.3900827608396327, 2.106503801662899, 2.523982437139943, 1.2247692034537863, 2.6464107228188505, 1.790959037023668]\n"
     ]
    }
   ],
   "source": [
    "x1_coords = [x[0] for x in X]  # your code goes here!\n",
    "print(x1_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the min, max and median. The min is done for you, and you get to complete the others. Yippee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.79882225, 0.78476658]),\n",
       " array([1.76134354, 1.53966376]),\n",
       " array([2.64641072, 1.83014267])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = [[0,0], [0,0], [0,0]] # initialize\n",
    "centroids[0] = X[x1_coords.index(min(x1_coords))]\n",
    "centroids[1] = X[x1_coords.index(np.median(x1_coords))] # your code goes here!\n",
    "centroids[2] = X[x1_coords.index(max(x1_coords))] # your code goes here!\n",
    "\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 2: Assigning to clusters\n",
    "\n",
    "Now that we have our first estimates of the cluster centroids. Let's loop over our data just once to get a feel for how we can assign each point to a cluster. We can start with just the first data point.\n",
    "\n",
    "Compute the distances from the first data point, `X[0]`, to each centroid. Store these distances in a list called `dists`. We also want to keep track of our current estimate of which cluster each data point belongs to, so we'll start a list for that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [0]*K # your code goes here!\n",
    "clusters = [-1]*len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41885651188011686, 0.9121891925310409, 1.842170070272393]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each point;\n",
    "#distance from that point to the list of centroids\n",
    "dists=[dist(X[0], centroid) for centroid in centroids]\n",
    "dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the index of the nearest centroid, and print out its coordinates for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.79882225 0.78476658]\n"
     ]
    }
   ],
   "source": [
    "assignment = dists.index(min(dists))\n",
    "print(assignment)\n",
    "print(centroids[assignment])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the 0th cluster (with centroid near (0.80, 0.79)) is the closest to this first data point. Thus, we assign it to cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[0] = assignment\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [0.79882225 0.78476658]\n",
      "1 0 [0.79882225 0.78476658]\n",
      "2 1 [1.76134354 1.53966376]\n",
      "3 0 [0.79882225 0.78476658]\n",
      "4 1 [1.76134354 1.53966376]\n",
      "5 2 [2.64641072 1.83014267]\n",
      "6 2 [2.64641072 1.83014267]\n",
      "7 2 [2.64641072 1.83014267]\n",
      "8 1 [1.76134354 1.53966376]\n",
      "9 2 [2.64641072 1.83014267]\n",
      "10 1 [1.76134354 1.53966376]\n"
     ]
    }
   ],
   "source": [
    "#for each point;\n",
    "#distance from that point to the list of centroids\n",
    "for i in range(len(X)):\n",
    "    dists=[dist(X[i], centroid) for centroid in centroids]\n",
    "\n",
    "    assignment = dists.index(min(dists))\n",
    "    print(i,assignment,centroids[assignment])\n",
    "    clusters[i] = assignment\n",
    "    clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 1, 2, 2, 2, 1, 2, 1]\n",
      "point  0  in in cluster  0\n",
      "point  1  in in cluster  0\n",
      "point  3  in in cluster  0\n",
      "point  2  in in cluster  1\n",
      "point  4  in in cluster  1\n",
      "point  8  in in cluster  1\n",
      "point  10  in in cluster  1\n",
      "point  5  in in cluster  2\n",
      "point  6  in in cluster  2\n",
      "point  7  in in cluster  2\n",
      "point  9  in in cluster  2\n"
     ]
    }
   ],
   "source": [
    "print(clusters)\n",
    "for j in range(K):\n",
    "    for n in range(len(X)):\n",
    "        if clusters[n]==j:\n",
    "            print('point ', n, ' in in cluster ', j)\n",
    "            #put a calculation of the mean of those points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 3:  Hierarchical clustering\n",
    "\n",
    "Suppose instead we decided we would like to cluster our data using hierarchical clustering. Each data point starts out as its own cluster, and (for example) on the first iteration, we must compare each pair of data points' distances. Then, we pick the minimum pair and pool them into the same cluster. As a convention, we will always use the lower index as the pair's cluster \"name\".\n",
    "\n",
    "Let's finish off this incomplete code to make the pairwise comparison of all data points' distances. Places where we need to make changes are marked as TODO. In the end, we want `closest_points` to be a length-2 list of the indices of the two data points in X that are nearest to one another, and `min_dist` should be the Euclidean distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92071706 1.18549396]\n",
      "[1.03598307 1.10911982]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist = np.inf # initialize\n",
    "closest_points = [-1, -1] # initialize\n",
    "clusters = list(range(len(X))) # initialize each point as its own cluster\n",
    "centroids = X # initialize each \"cluster\" centroid as the data point itself\n",
    "for i in range(len(X)):\n",
    "    for j in range(i+1, len(X)): #start j after i to avoid overcounting i,j and j,i\n",
    "        # compute the distance between X[i] and X[j]\n",
    "        new_dist = dist(X[i], X[j]) # TODO\n",
    "        # replace min_dist and closest_points with the new pair's info if it's closer\n",
    "        if new_dist<min_dist:\n",
    "            min_dist = new_dist \n",
    "            closest_points = [i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3] 0.13827241442138283\n"
     ]
    }
   ],
   "source": [
    "print(closest_points, min_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `closest_points` should be [0, 3], so we want to reassign `clusters[3] = 0` (instead of its original value of 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign to the cluster\n",
    "clusters[max(closest_points)] = min(closest_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to recompute the centroid of cluster 0, or in general, `min(closest_points)`.  There are many ways to do this, including of course the brute force for loop. Here's a slightly more elegant list comprehension to obtain the $X_1$ and $X_2$ coordinates from each data point that is in cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_coords = [X[k][0] if clusters[k]==0 else 0 for k in range(len(X))]\n",
    "x2_coords = [X[k][1] if clusters[k]==0 else 0 for k in range(len(X))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to compute the means in each coordinate, we need the number of data points assigned to this cluster. Obviously, you could just write in \"2\" and go about your business, but try to come up with a more general computation to get this. Then, use the `x1_coords` and `x2_coords` from above and `n_cluster_0` from below to compute the updated centroid of cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_0 = 0 # TODO\n",
    "centroids[0] = [0, 0] # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, as a matter of bookkeeping, we might want to set the centroid for cluster 3 (which was just \"absorbed\" into cluster 0) to some fill-value that would alert us if we accidentally used it in a calculation when we should have used the centroid for cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[max(closest_points)] = np.full(shape=centroids[max(closest_points)].shape, fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it! One complete iteration of hierarchical clustering. Now we would again do the distance calculation for each cluster (most of which are still a single data point), and merge the two closest clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus for variogram HW:\n",
    "\n",
    "Now suppose our data is *streaming*- we slowly add observations one at a time, instead of seeing the entire data set at once.  We are still interested in the mean, so if we stream the data set `[4,6,0,10, ...]`, we first compute the mean of the the first data point `[4]`, then we recompute the mean of the first two points `[4,6]`, then we recompute the mean of three `[4,6,0]`, and so forth.\n",
    "\n",
    "**Result**: The following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$\n",
    "\n",
    "Note that you can get an expression for $\\bar{x}_{n-1}$ by simply replacing $n$ in Equation 1 above with $n-1$.\n",
    "**Proof**:\n",
    "We'll start with $\\bar{x}_n$ and massage it until we get the righthand side of the formula\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\nonumber \\bar{x}_n &=& \\frac{1}{n} \\sum_{k=1}^n x_k \\\\\n",
    "&=& \\frac{1}{n} \\sum_{k=1}^{n-1} x_k + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n-1}{n-1}\\frac{1}{n} \\sum_{k=1}^{n-1} x_k + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n-1}{n} \\left(\\frac{1}{n-1} \\sum_{k=1}^{n-1} x_k\\right) + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n-1}{n} \\bar{x}_{n-1} + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n}{n}\\bar{x}_{n-1} - \\frac{1}{n}\\bar{x}_{n-1} + \\frac{1}{n}x_n \\\\\n",
    "&=&  \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n} \\quad \\checkmark\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Bonus!\n",
    "\n",
    "As you worked through the previous exercises, it may have struck you that it would be convenient to have a `Cluster` object defined, so we can have nice attributes to cleanly keep track of things like which data points are in a given cluster, what the centroid of the cluster is, and so forth. It sure would be convenient to have member functions to update the cluster centroid when a new data point is added to the cluster.\n",
    "\n",
    "Below is a helpful template. If you're looking for some extra fun for the weekend, have a crack at filling it in! Object-oriented certainly helps keep things tidy - try completing the clustering exercises from above using your shiny new `Cluster` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we want to do with clusters:**\n",
    "- intialize them with one or more points\n",
    "- append new points to them\n",
    "- need to maybe remove points if they change clusters\n",
    "- recompute the mean of the cluster, in any number of dimensions\n",
    "\n",
    "we get access to functions like; say `y` is a `Cluster`: `y.add_point`\n",
    "\n",
    "FINAL ALGORITHMS:\n",
    "\n",
    "for point in points:\n",
    "\n",
    "    dist(point to each cluster)\n",
    "    \n",
    "    cluster.append(point)\n",
    "    (maybe also remove that point from its prior cluster?)\n",
    "\n",
    "for clustser in clusters:\n",
    "\n",
    "    self.update_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    \n",
    "    def __init__(self, dim, n=0, X=None):\n",
    "        '''\n",
    "        dim = number of dimensions for each data point\n",
    "        n = number of data points to start with\n",
    "        X = list of data points (list of lists, or other array-like objects)\n",
    "        '''\n",
    "        self.dim = dim\n",
    "        self.n = n\n",
    "        self.X = X if n != 1 else [X]\n",
    "        self.centroid = self.compute_centroid()\n",
    "        \n",
    "    def add_data_pt(self, Xnew):\n",
    "        '''\n",
    "        Add a data point Xnew to the cluster.\n",
    "        Depending on how you structure your code, this routine might want to call update_centroid(...)\n",
    "        '''\n",
    "        # TODO\n",
    "        self.n+=1\n",
    "        self.X.append(Xnew)\n",
    "        self.centroid=self.compute_centroid()\n",
    "#         self.update_centroid(self, Xnew)\n",
    "        \n",
    "        #added line?  what if it's the first data point?\n",
    "        \n",
    "    def update_centroid(self, Xnew):\n",
    "        '''\n",
    "        Use formula for online update of the mean to update each component of the centroid using n and Xnew\n",
    "            m[n] = m[n-1] + (a[n] - m[n-1])/n\n",
    "        (https://math.stackexchange.com/questions/106700/incremental-averageing)\n",
    "        '''\n",
    "        # TODO\n",
    "        #lazy way instead of \"streaming mean:\n",
    "        \n",
    "        \n",
    "    def compute_centroid(self):\n",
    "        '''\n",
    "        Compute the centroid the hard way, by taking the mean of all data points in the cluster (self.X)\n",
    "        '''\n",
    "        centr = [np.nan]*self.dim\n",
    "        # TODO\n",
    "        for d in range(self.dim):\n",
    "            centr[d]=np.mean([x[d] for x in self.X])\n",
    "        return centr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0]]\n",
      "[1.0, 0.0]\n",
      "[[1, 0], [4, 1]]\n",
      "[2.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "C1=Cluster(2, n=1, X=[1,0])\n",
    "print(C1.X)\n",
    "print(C1.centroid)\n",
    "C1.add_data_pt([4,1])\n",
    "print(C1.X)\n",
    "print(C1.centroid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
